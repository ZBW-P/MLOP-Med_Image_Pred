name: xray-etl

volumes:
  xraydata:

services:
  extract-data:
    container_name: etl_xray_extract
    image: python:3.11
    user: root
    volumes:
      - xraydata:/data
    working_dir: /data
    command:
      - bash
      - -c
      - |
        set -e

        echo "Resetting dataset directory..."
        rm -rf xray_dataset
        mkdir -p xray_dataset
        cd xray_dataset

        echo "Downloading X-ray dataset zip..."
        curl -L -o xraynumpy.zip https://www.kaggle.com/api/v1/datasets/download/bibhash123/xraynumpy

        echo "Unzipping X-ray dataset..."
        unzip -q xraynumpy.zip
        rm -f xraynumpy.zip

        echo "Downloading CSV metadata..."
        curl -L -o train.csv.zip "https://storage.googleapis.com/kaggle-data-sets/1042002/1794153/compressed/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1746941105&Signature=kgpzZ9QZD5dD5gG5gbEqCznf%2B6qK%2Bh5lPx59s0BVQ1qjNUZ0QJlMbQKkwBvJAiYmz6HFA8apXjqD2dxz1cTJCTmQrMpGgpco8caxE86Wnamh0Mp5emZEc5eFYv3oYUHFqjJHGywTquOQfAFu3UPJOTjA%2BlG47pq0eafR8FoDmTbFcPcN841pMKyrUtXwCPQ8NnwM7C6bNv6oLnNHsHa8KCu4ov9asF7CseRRiSl%2FKUDxAE2grpYjanb%2BS6bxA8ZJOA0%2FA2c6JZ%2BGEzPEc4t4ScI3xxiDxZhleYw%2FJXi4FIOBkTRA39yOSxeU%2Bl9JuM%2F0ue0U6eoqJrQ0tQRorUkDEg%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip"

        echo "Unzipping CSV metadata..."
        unzip -q train.csv.zip
        rm -f train.csv.zip

        echo "Listing contents of /data after extract stage:"
        ls -l /data/xray_dataset

  transform-data:
    container_name: etl_xray_transform
    image: python:3.11
    volumes:
      - xraydata:/data
      - ./transform.py:/data/xray_dataset/transform.py:ro
    working_dir: /data/xray_dataset
    command:
      - bash
      - -c
      - |
        set -e

        echo "Installing Python dependencies..."
        pip install pandas pillow numpy scikit-learn

        echo "Running transform.py..."
        python3 transform.py

        echo "Listing contents of /data/final_datasets after transform stage:"
        find /data/final_datasets -type f | head -n 10

  load-data:
    container_name: etl_xray_load
    image: rclone/rclone:latest
    volumes:
      - xraydata:/data
      - ~/.config/rclone/rclone.conf:/root/.config/rclone/rclone.conf:ro
    entrypoint: /bin/sh
    command:
      - -c
      - |
        if [ -z "$RCLONE_CONTAINER" ]; then
          echo "ERROR: RCLONE_CONTAINER is not set"
          exit 1
        fi
        echo "Cleaning up existing contents in the remote container..."
        rclone delete chi_tacc:$RCLONE_CONTAINER --rmdirs || true

        echo "Uploading dataset to remote container..."
        rclone copy /data chi_tacc:$RCLONE_CONTAINER \
        --progress \
        --transfers=32 \
        --checkers=16 \
        --multi-thread-streams=4 \
        --fast-list

        echo "Listing directories in the remote container after upload:"
        rclone lsd chi_tacc:$RCLONE_CONTAINER
